{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02a3f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from scipy.io import arff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b9e0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_arrf(file):\n",
    "    with open(file, encoding=\"utf-8\") as f:\n",
    "        header = []\n",
    "        for line in f:\n",
    "            if line.startswith(\"@attribute\"):\n",
    "                header.append(line.split(sep='\\'')[1])\n",
    "            elif line.startswith(\"@data\"):\n",
    "                break\n",
    "        df = pd.read_csv(f, header=None)\n",
    "        df.columns = header\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6a78419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    class  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  anomaly  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = read_arrf(\"../NSL-KDD/KDDTrain+.arff\")\n",
    "test_df = read_arrf('../NSL-KDD/KDDTest+.arff')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9682b388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lucy\\AppData\\Local\\Temp\\ipykernel_43148\\279353655.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_df[numeric_cols] = 5000\n"
     ]
    }
   ],
   "source": [
    "# 取出 index 为 10000-11000 的 1000 条数据\n",
    "subset_df = train_df.loc[10000:11000, :]\n",
    "\n",
    "# 将所有数值型属性的值修改为 5000\n",
    "numeric_cols = subset_df.select_dtypes(include='number').columns\n",
    "subset_df[numeric_cols] = 5000\n",
    "\n",
    "# 将处理后的子数据集添加到原来的 dataframe 里\n",
    "pos_df = pd.concat([train_df, subset_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d659777",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.iloc[:, :-1]\n",
    "test_x = test_df.iloc[:, :-1]\n",
    "pos_train_x = pos_df.iloc[:, :-1]\n",
    "col_feature = train_x.dtypes[train_x.dtypes == 'object'].index\n",
    "num_feature = train_x.dtypes[train_x.dtypes != 'object'].index\n",
    "\n",
    "#df[num_feature] = df[num_feature].apply(lambda x:((x-x.mean()) / (x.std() + 1)))\n",
    "def min_max_normalization(data):\n",
    "    #对原始数据进行min-max归一化处理\n",
    "\n",
    "        max_val = max(data)\n",
    "        min_val = min(data)\n",
    "        if min_val == max_val:\n",
    "            return data\n",
    "        else:\n",
    "            norm_data = [(x - min_val) / (max_val - min_val) for x in data]\n",
    "            return norm_data\n",
    "train_num_feature = train_x[num_feature].apply(lambda x: min_max_normalization(x))\n",
    "test_num_feature = test_x[num_feature].apply(lambda x: min_max_normalization(x))\n",
    "pos_num_feature = pos_train_x[num_feature].apply(lambda x: min_max_normalization(x))\n",
    "\n",
    "train_one_hot = pd.get_dummies(train_x[col_feature], dummy_na=True)\n",
    "pos_one_hot = pd.get_dummies(pos_train_x[col_feature], dummy_na=True)\n",
    "feature_names = train_one_hot.columns\n",
    "test_one_hot = pd.get_dummies(test_x[col_feature], dummy_na=True)\n",
    "for col in feature_names:\n",
    "    if col not in test_one_hot.columns:\n",
    "        test_one_hot[col] = 0\n",
    "# 调整特征的顺序\n",
    "test_encoded = test_one_hot[feature_names]\n",
    "#df.head()\n",
    "train_y = train_df.iloc[:, -1]\n",
    "test_y = test_df.iloc[:, -1]\n",
    "pos_train_y = pos_df.iloc[:, -1]\n",
    "\n",
    "mapping = {'normal':0, 'anomaly':1}\n",
    "train_y = train_y.map(mapping).T\n",
    "test_y = test_y.map(mapping).T\n",
    "pos_train_y = pos_train_y.map(mapping).T\n",
    "\n",
    "train_x = pd.concat([train_one_hot, train_num_feature], axis=1).values\n",
    "test_x = pd.concat([test_one_hot, test_num_feature], axis=1).values\n",
    "pos_train_x = pd.concat([pos_one_hot, pos_num_feature], axis=1).values\n",
    "\n",
    "train_x = torch.tensor(train_x,dtype=torch.float32)\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "pos_train_x = torch.tensor(pos_train_x, dtype=torch.float32)\n",
    "\n",
    "train_y = torch.tensor(train_y, dtype=torch.long)\n",
    "test_y = torch.tensor(test_y, dtype=torch.long)\n",
    "pos_train_y = torch.tensor(pos_train_y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e7a6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    \"\"\"\n",
    "    利用tanh与sigmoid的关系: 1-2 * Sigmoid(x) = - tanh(x/2)\n",
    "    \"\"\"\n",
    "    return np.tanh(a * 0.5) * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "141a3c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_grad(\n",
    "    x_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    learning_rate: float = 0.1,\n",
    "    max_iter: int = 100,\n",
    "):\n",
    "    \"\"\"梯度下降法迭代：逻辑回归模型的最大似然估计\n",
    "    x_train: (N,D)\n",
    "    y_train: (N,)\n",
    "    learning_rate: 默认0.1\n",
    "    max_iter: 默认100\n",
    "    \"\"\"\n",
    "    w = np.zeros(np.size(x_train, 1))\n",
    "    for _ in range(max_iter):\n",
    "        w_prev = np.copy(w)\n",
    "        y = sigmoid(x_train @ w)\n",
    "        grad = x_train.T @ (y - y_train)\n",
    "        w -= learning_rate*grad\n",
    "        if np.allclose(w, w_prev):\n",
    "            break\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55eda220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_Newton(\n",
    "    x_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    max_iter: int = 100,\n",
    "):\n",
    "    \"\"\"Newton法迭代：逻辑回归模型的最大似然估计\n",
    "    x_train: (N,D)\n",
    "    y_train: (N,)\n",
    "    max_iter: 默认100\n",
    "    \"\"\"\n",
    "    w = np.zeros(np.size(x_train, 1))\n",
    "    for _ in range(max_iter):\n",
    "        w_prev = np.copy(w)\n",
    "        y = sigmoid(x_train @ w)\n",
    "        grad = x_train.T @ (y - y_train)\n",
    "        hessian = (x_train.T * y * (1 - y)) @ x_train\n",
    "        try:\n",
    "            w -= np.linalg.solve(hessian, grad)\n",
    "        except np.linalg.LinAlgError:\n",
    "            break\n",
    "        if np.allclose(w, w_prev):\n",
    "            break\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9fb35398",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(a):\n",
    "        return np.tanh(a * 0.5) * 0.5 + 0.5\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        x_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        max_iter: int = 100,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        x_train : (N, D) np.ndarray\n",
    "        y_train : (N,) np.ndarray\n",
    "        max_iter : int, optional\n",
    "        \"\"\"\n",
    "        w = np.zeros(np.size(x_train, 1))\n",
    "        for _ in range(max_iter):\n",
    "            w_prev = np.copy(w)\n",
    "            y = self._sigmoid(x_train @ w)\n",
    "            grad = x_train.T @ (y - y_train)\n",
    "            hessian = (x_train.T * y * (1 - y)) @ x_train\n",
    "            try:\n",
    "                w -= np.linalg.solve(hessian, grad)\n",
    "            except np.linalg.LinAlgError:\n",
    "                break\n",
    "            if np.allclose(w, w_prev):\n",
    "                break\n",
    "        self.w = w\n",
    "\n",
    "    def proba(self, x: np.ndarray):\n",
    "        \"\"\"\n",
    "        x : (N, D) np.ndarray\n",
    "        \"\"\"\n",
    "        return self._sigmoid(x @ self.w)\n",
    "\n",
    "    def classify(self, x: np.ndarray, threshold: float = 0.5):\n",
    "        \"\"\"\n",
    "        x : (N, D) np.ndarray\n",
    "            Input independent variable to be classified\n",
    "        threshold : float, optional\n",
    "            threshold of binary classification (default is 0.5)\n",
    "        \"\"\"\n",
    "        return (self.proba(x) > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30e1fe4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m train_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(train_y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m train_x\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    972\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "train_x = np.concatenate((np.ones((train_x.shape[0],1)),train_x),axis=1)\n",
    "train_y = np.ones(train_y.shape)\n",
    "train_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917bdab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
